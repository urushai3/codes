{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1sFK788Ni5LBOYVUKE5U2aFdH2qq17htV","timestamp":1707472504975}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install fuzzywuzzy[speedup]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d_liBseRXUeN","executionInfo":{"status":"ok","timestamp":1707584640989,"user_tz":-330,"elapsed":13786,"user":{"displayName":"Uroosha Rahat","userId":"13442631070779918669"}},"outputId":"65702890-1598-436c-bf37-d7983ae9592a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting fuzzywuzzy[speedup]\n","  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n","Collecting python-levenshtein>=0.12 (from fuzzywuzzy[speedup])\n","  Downloading python_Levenshtein-0.24.0-py3-none-any.whl (9.4 kB)\n","Collecting Levenshtein==0.24.0 (from python-levenshtein>=0.12->fuzzywuzzy[speedup])\n","  Downloading Levenshtein-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (177 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting rapidfuzz<4.0.0,>=3.1.0 (from Levenshtein==0.24.0->python-levenshtein>=0.12->fuzzywuzzy[speedup])\n","  Downloading rapidfuzz-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: fuzzywuzzy, rapidfuzz, Levenshtein, python-levenshtein\n","Successfully installed Levenshtein-0.24.0 fuzzywuzzy-0.18.0 python-levenshtein-0.24.0 rapidfuzz-3.6.1\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","\n","# Read the data from the CSV file\n","df = pd.read_csv(\"/content/Uroosha's names sheet - _A_ Only with _.csv\")\n","\n","# Split the \"Investigators\" column into separate rows by pipe delimiter\n","df[\"Unclubbed_Investigators\"] = df[\"PI\"].str.split(\"|\")\n","\n","# Explode the split \"Unclubbed_Investigators\" column\n","df = df.explode(\"Unclubbed_Investigators\")\n","\n","# Clean up the \"Unclubbed_Investigators\" column by removing leading/trailing spaces\n","df[\"Unclubbed_Investigators\"] = df[\"Unclubbed_Investigators\"].str.strip()\n","\n","# # Further split each investigator entry by comma delimiter and create new columns\n","# df = pd.DataFrame(df[\"Unclubbed_Investigators\"].str.split(\",\", expand=True))\n","\n","# # Filter rows where \"PRINCIPAL_INVESTIGATOR\" is present in the first column\n","# filtered_df = df[df[df.columns[0]].str.contains(\"PRINCIPAL_INVESTIGATOR\", na=False)]\n","\n","# # Remove occurrences of prefixes and leading/trailing spaces in all columns\n","# filtered_df = filtered_df.apply(lambda row: row.str.strip().str.replace(r\"^(A\\/Prof\\.|A\\/Prof|Prof|Prof.|Dr\\.)\\s+\", \"\", regex=True))\n","\n","# # Keep only unique entries based on column 1\n","# filtered_df = filtered_df.drop_duplicates(subset=df.columns[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":581},"id":"bQnFTVou-Bid","executionInfo":{"status":"error","timestamp":1707585183318,"user_tz":-330,"elapsed":18,"user":{"displayName":"Uroosha Rahat","userId":"13442631070779918669"}},"outputId":"e26bc5bf-739f-454a-815e-01e06e15cf70"},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"'PI'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'PI'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-108a69a7a634>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Split the \"Investigators\" column into separate rows by pipe delimiter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Unclubbed_Investigators\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"PI\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"|\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Explode the split \"Unclubbed_Investigators\" column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'PI'"]}]},{"cell_type":"code","source":["filtered_df=df[\"Unclubbed_Investigators\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":581},"id":"tL2Kfj0v_AmB","executionInfo":{"status":"error","timestamp":1707585183735,"user_tz":-330,"elapsed":12,"user":{"displayName":"Uroosha Rahat","userId":"13442631070779918669"}},"outputId":"ecd52b29-75fe-4d23-ccdb-ad7f5a56e861"},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"'Unclubbed_Investigators'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Unclubbed_Investigators'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-b222ca46d47f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfiltered_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Unclubbed_Investigators\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Unclubbed_Investigators'"]}]},{"cell_type":"code","source":["# Save the modified DataFrame to a new CSV file with UTF-8 encoding\n","filtered_df.to_csv(\"name.csv\", index=False, header=False, encoding='utf-8-sig')"],"metadata":{"id":"N-aQtBnJ-ct6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# With Fuzzy String Match Implementation"],"metadata":{"id":"QJUvQJTkicSY"}},{"cell_type":"code","source":["import pandas as pd\n","from fuzzywuzzy import fuzz\n","\n","# Read the data from the CSV file\n","df = pd.read_csv(\"Breast_cancer.csv\")\n","\n","# Split the \"Investigators\" column into separate rows by pipe delimiter\n","df[\"Unclubbed_Investigators\"] = df[\"Investigators\"].str.split(\"|\")\n","\n","# Explode the split \"Unclubbed_Investigators\" column\n","df = df.explode(\"Unclubbed_Investigators\")\n","\n","# Clean up the \"Unclubbed_Investigators\" column by removing leading/trailing spaces\n","df[\"Unclubbed_Investigators\"] = df[\"Unclubbed_Investigators\"].str.strip()\n","\n","# Further split each investigator entry by comma delimiter and create new columns\n","df = pd.DataFrame(df[\"Unclubbed_Investigators\"].str.split(\",\", expand=True))\n","\n","# Filter rows where \"PRINCIPAL_INVESTIGATOR\" is present in the first column\n","filtered_df = df[df[df.columns[0]].str.contains(\"PRINCIPAL_INVESTIGATOR\", na=False)]\n","\n","# Remove occurrences of prefixes and leading/trailing spaces in all columns\n","filtered_df = filtered_df.apply(lambda row: row.str.strip().str.replace(r\"^(A\\/Prof\\.|A\\/Prof|Prof|Prof.|Dr\\.)\\s+\", \"\", regex=True))\n","\n","# Keep only unique entries based on column 1\n","filtered_df = filtered_df.drop_duplicates(subset=df.columns[1])\n","\n","# Define a function to calculate fuzzy string similarity\n","def similar(a, b):\n","    return fuzz.token_sort_ratio(a, b)\n","\n","# Function to find and remove duplicates based on fuzzy matching\n","def remove_duplicates(df):\n","    duplicates = set()\n","    unique_names = df[df.columns[1]].unique()\n","    for i, name1 in enumerate(unique_names):\n","        if name1 in duplicates:\n","            continue\n","        for j, name2 in enumerate(unique_names[i+1:], i+1):\n","            if similar(name1, name2) > 80:  # Adjust the threshold as needed\n","                duplicates.add(name2)\n","    df = df[~df[df.columns[1]].isin(duplicates)]\n","    return df\n","\n","# Remove duplicates based on fuzzy string matching\n","filtered_df = remove_duplicates(filtered_df)\n","\n","# Sort unique investigators in alphabetical order by column 1\n","filtered_df = filtered_df.sort_values(by=df.columns[1], ascending=True)\n","\n","# Save the modified DataFrame to a new CSV file with UTF-8 encoding\n","filtered_df.to_csv(\"Breast_cancer_cleaned_fuzzy.csv\", index=False, header=False, encoding='utf-8-sig')\n","\n","print(\"Data is cleaned\")"],"metadata":{"id":"wg0fh1syVZ-k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## With Fuzzy String Match Implementation and QCing the discarded data as well"],"metadata":{"id":"lz8btjQUlbDa"}},{"cell_type":"code","source":["import pandas as pd\n","from fuzzywuzzy import fuzz\n","\n","# Read the data from the CSV file\n","df = pd.read_csv(\"Lung_cancer.csv\")\n","\n","# Split the \"Investigators\" column into separate rows by pipe delimiter\n","df[\"Unclubbed_Investigators\"] = df[\"Investigators\"].str.split(\"|\")\n","\n","# Explode the split \"Unclubbed_Investigators\" column\n","df = df.explode(\"Unclubbed_Investigators\")\n","\n","# Clean up the \"Unclubbed_Investigators\" column by removing leading/trailing spaces\n","df[\"Unclubbed_Investigators\"] = df[\"Unclubbed_Investigators\"].str.strip()\n","\n","# Further split each investigator entry by comma delimiter and create new columns\n","df = pd.DataFrame(df[\"Unclubbed_Investigators\"].str.split(\",\", expand=True))\n","\n","# Filter rows where \"PRINCIPAL_INVESTIGATOR\" is present in the first column\n","filtered_df = df[df[df.columns[0]].str.contains(\"PRINCIPAL_INVESTIGATOR\", na=False)]\n","\n","# Drop the first column as it contains only \"PRINCIPAL_INVESTIGATOR\"\n","filtered_df = filtered_df.drop(filtered_df.columns[0], axis=1)\n","\n","# Remove occurrences of prefixes and leading/trailing spaces in all columns\n","filtered_df = filtered_df.apply(lambda row: row.str.strip().str.replace(r\"^(A\\/Prof\\.|A\\/Prof|Prof|Prof.|Dr|Dr\\.)\\s+\", \"\", regex=True))\n","\n","# # Sort unique investigators in alphabetical order\n","filtered_df = filtered_df.sort_values(by=df.columns[1], ascending=True)\n","\n","# Get full name from the first column and affiliations from merged remaining columns\n","filtered_df[\"Affiliations\"] = filtered_df.iloc[:, 1:].apply(lambda x: ', '.join(x.dropna()), axis=1)\n","filtered_df[\"full_name\"] = filtered_df.iloc[:, 0]\n","# Keep only the desired columns and remove duplicates\n","filtered_df = filtered_df[[\"full_name\", \"Affiliations\"]].drop_duplicates(subset=\"full_name\")\n","\n","# Sort by full name\n","filtered_df = filtered_df.sort_values(by=\"full_name\", ascending=True)\n","\n","def similar_with(name1, aff1, name2, aff2, name_weight=0.8, aff_weight=0.2):\n","    name_similarity = fuzz.token_sort_ratio(name1, name2)\n","    aff_similarity = fuzz.token_sort_ratio(aff1, aff2)\n","    weighted_similarity = (name_similarity * name_weight) + (aff_similarity * aff_weight)\n","    return weighted_similarity\n","\n","# Function to find and remove duplicates based on fuzzy matching with weighted components\n","def remove_duplicates(df):\n","    duplicates = set()\n","    unique_rows = df.values.tolist()\n","    discarded_rows = []\n","\n","    for i, row1 in enumerate(unique_rows):\n","        if row1[0] in duplicates:\n","            continue\n","        for j, row2 in enumerate(unique_rows[i + 1:], i + 1):\n","            similarity = similar_with(row1[0], row1[1], row2[0], row2[1])\n","            if similarity > 85:  # Adjust the threshold as needed\n","                duplicates.add(row2[0])\n","                discarded_rows.append((row2, row1, similarity))\n","\n","    filtered_df = df[~df[df.columns[0]].isin(duplicates)]\n","    return filtered_df, discarded_rows\n","\n","# Remove duplicates based on fuzzy string matching including affiliation\n","filtered_df, discarded_rows = remove_duplicates(filtered_df)\n","\n","# Clean the \"Discarded_Row\" and \"Matched_Part\" columns in discarded_rows\n","discarded_rows = [\n","    [\", \".join([item for item in row[0] if item]), \", \".join([item for item in row[1] if item]), row[2]]\n","    for row in discarded_rows\n","]\n","\n","# Save the discarded rows to a separate CSV file with entire row information\n","discarded_df = pd.DataFrame({\n","    \"Discarded_Row\": [item[0] for item in discarded_rows],\n","    \"Matched_Part\": [item[1] for item in discarded_rows],\n","    \"Similarity_Percentage\": [item[2] for item in discarded_rows]\n","})\n","discarded_df.to_csv(\"lung_cancer_discarded_names_fuzzy.csv\", index=False)\n","\n","# # Save the modified DataFrame to a new CSV file with UTF-8 encoding\n","filtered_df.to_csv(\"Lung_cancer_cleaned_fuzzy.csv\", index=False, header=False, encoding='utf-8-sig')\n","\n","print(\"Data is cleaned\")"],"metadata":{"id":"sOcZT8HWQNPL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707469135397,"user_tz":-330,"elapsed":474991,"user":{"displayName":"Piyush Gajbhiye","userId":"16708562544684728252"}},"outputId":"86b1b77d-b5a3-41c6-cd7e-34b544bd33fd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Data is cleaned\n"]}]}]}